{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into stratified train, val, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5410\n",
      "Negatives: 1714, Positives: 3696\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5410 data points\n",
    "Train, Val, Test = 80%, 10%, 10% = 4328, 541, 541\n",
    "\"\"\"\n",
    "\n",
    "negative_indices = np.random.permutation(negatives.index.values)\n",
    "positive_indices = np.random.permutation(positives.index.values)\n",
    "\n",
    "neg_train, neg_val, neg_test = np.split(negative_indices, [round(0.8 * neg_size), round(0.9 * neg_size)])\n",
    "pos_train, pos_val, pos_test = np.split(positive_indices, [round(0.8 * pos_size), round(0.9 * pos_size)])\n",
    "\n",
    "train = np.concatenate((neg_train, pos_train))\n",
    "val = np.concatenate((neg_val, pos_val))\n",
    "test = np.concatenate((neg_test, pos_test))\n",
    "\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(val)\n",
    "np.random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: (Train: 4328, Val: 541, Test: 541)\n",
      "Negatives: (Train: 1371, Val: 172, Test: 171)\n",
      "Positives: (Train: 2957, Val: 369, Test: 370)\n"
     ]
    }
   ],
   "source": [
    "trainset = df.iloc[train]\n",
    "valset = df.iloc[val]\n",
    "testset = df.iloc[test]\n",
    "\n",
    "print(f\"Length: (Train: {len(trainset)}, Val: {len(valset)}, Test: {len(testset)})\")\n",
    "print(f\"Negatives: (Train: {sum(trainset['label']==0)}, Val: {sum(valset['label']==0)}, Test: {sum(testset['label']==0)})\")\n",
    "print(f\"Positives: (Train: {sum(trainset['label']==1)}, Val: {sum(valset['label']==1)}, Test: {sum(testset['label']==1)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.to_csv(\"data/train.csv\", index=False)\n",
    "valset.to_csv(\"data/val.csv\", index=False)\n",
    "testset.to_csv(\"data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Train Data to 50% neg 50% pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from BERTweet.TweetNormalizer import normalizeTweet\n",
    "from eda_nlp.code.eda import eda\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_aug = np.full(neg_size, pos_size // neg_size)\n",
    "num_aug[:pos_size % neg_size] += 1\n",
    "np.random.shuffle(num_aug)\n",
    "num_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sr = 0.1 # synonym replacement\n",
    "alpha_ri = 0.1 # random insertion\n",
    "alpha_rs = 0.0 # random swap\n",
    "alpha_rd = 0.0 # random deletion\n",
    "\n",
    "augmented_negatives = {\"label\": [], \"tweet\": []}\n",
    "\n",
    "for i, line in enumerate(negatives.iloc):\n",
    "    label = line[\"label\"]\n",
    "    sentence = normalizeTweet(line[\"tweet\"])\n",
    "    aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug[i]-1)\n",
    "    for aug_sentence in aug_sentences:\n",
    "        augmented_negatives[\"label\"].append(label)\n",
    "        augmented_negatives[\"tweet\"].append(aug_sentence)\n",
    "\n",
    "augmented_negatives = pd.DataFrame(augmented_negatives)\n",
    "augmented_df = pd.concat([augmented_negatives, positives[[\"label\", \"tweet\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_csv(\"data/train_augment_5050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5914\n",
      "Negatives: 2957, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_augment_5050.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Train Data to 75% neg 25% pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from BERTweet.TweetNormalizer import normalizeTweet\n",
    "from eda_nlp.code.eda import eda\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 7, ..., 6, 6, 7])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_aug = np.full(neg_size, 3 * pos_size // neg_size)\n",
    "num_aug[:3 * pos_size % neg_size] += 1\n",
    "np.random.shuffle(num_aug)\n",
    "num_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sr = 0.1 # synonym replacement\n",
    "alpha_ri = 0.1 # random insertion\n",
    "alpha_rs = 0.1 # random swap\n",
    "alpha_rd = 0.1 # random deletion\n",
    "\n",
    "augmented_negatives = {\"label\": [], \"tweet\": []}\n",
    "\n",
    "for i, line in enumerate(negatives.iloc):\n",
    "    label = line[\"label\"]\n",
    "    sentence = normalizeTweet(line[\"tweet\"])\n",
    "    aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug[i]-1)\n",
    "    for aug_sentence in aug_sentences:\n",
    "        augmented_negatives[\"label\"].append(label)\n",
    "        augmented_negatives[\"tweet\"].append(aug_sentence)\n",
    "\n",
    "augmented_negatives = pd.DataFrame(augmented_negatives)\n",
    "augmented_df = pd.concat([augmented_negatives, positives[[\"label\", \"tweet\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_csv(\"data/train_augment_7525.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 11828\n",
      "Negatives: 8871, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_augment_7525.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from BERTweet.TweetNormalizer import normalizeTweet\n",
    "from eda_nlp.code.eda import eda\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textattack.attack_results.successful_attack_result import SuccessfulAttackResult\n",
    "\n",
    "original = []\n",
    "perturbed = []\n",
    "\n",
    "with open(\"textattackresults.pkl\", \"rb\") as f:\n",
    "    attacks = pickle.load(f)\n",
    "    for a in attacks:\n",
    "        if isinstance(a, SuccessfulAttackResult):\n",
    "            original.append(a.original_text())\n",
    "            perturbed.append(a.perturbed_text())\n",
    "\n",
    "atk = pd.DataFrame({\"original_text\": original, \"perturbed_text\": perturbed})\n",
    "atk = atk[:len(atk)//2]\n",
    "len(atk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atk = pd.read_csv(\"attacks.csv\")\n",
    "# atk = atk[atk['result_type'] == \"Successful\"]\n",
    "# atk[\"original_text\"]  = [i.replace('[[', '').replace(']]', '') for i in atk[\"original_text\"]]\n",
    "# atk[\"perturbed_text\"] = [i.replace('[[', '').replace(']]', '') for i in atk[\"perturbed_text\"]]\n",
    "\n",
    "# atk = atk[:len(atk)//2]\n",
    "# len(atk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk_dict = {o: p for o, p in atk[['original_text', 'perturbed_text']].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "new_tweets = []\n",
    "\n",
    "for i, line in enumerate(df.iloc):\n",
    "    label = line[\"label\"]\n",
    "    sentence = normalizeTweet(line[\"tweet\"])\n",
    "\n",
    "    if sentence in atk_dict:\n",
    "        new_tweets.append(atk_dict[sentence])\n",
    "    else:\n",
    "        new_tweets.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"] = new_tweets\n",
    "df.to_csv(\"data/train_ta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_ta.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25242 0.9\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.9\n",
    "num_samples = int(pos_size * ratio / (1-ratio))\n",
    "num_new = num_samples - neg_size\n",
    "print(num_new, num_samples/(num_samples + pos_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"data/sentiment140.csv\", names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"], encoding=\"ISO-8859-1\")\n",
    "new_samples = new_df.sample(num_new)\n",
    "new_samples = pd.DataFrame({\"label\": np.zeros(len(new_samples), dtype=int), \"tweet\": new_samples['text'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aww. Well that was quick. Poor Maria. At least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@AubreyODay Right? Especially the part about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@azandiaMJBB Oh I do agree - vegging out occas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>If you've emailed or messaged me this week, I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@spazziness stress all day long... need to fig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25237</th>\n",
       "      <td>0</td>\n",
       "      <td>@ChreeesDunn Good luck with that dude. Should ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25238</th>\n",
       "      <td>0</td>\n",
       "      <td>@IamAdamFierce adammmmmm!! I kept coming to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25239</th>\n",
       "      <td>0</td>\n",
       "      <td>@peterfacinelli Just make sure its not an inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25240</th>\n",
       "      <td>0</td>\n",
       "      <td>@tweet_homes gotta watch out for those telemar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25241</th>\n",
       "      <td>0</td>\n",
       "      <td>Gooood morning twitter world. Finally had a lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "0          0  Aww. Well that was quick. Poor Maria. At least...\n",
       "1          0  @AubreyODay Right? Especially the part about h...\n",
       "2          0  @azandiaMJBB Oh I do agree - vegging out occas...\n",
       "3          0  If you've emailed or messaged me this week, I'...\n",
       "4          0  @spazziness stress all day long... need to fig...\n",
       "...      ...                                                ...\n",
       "25237      0  @ChreeesDunn Good luck with that dude. Should ...\n",
       "25238      0  @IamAdamFierce adammmmmm!! I kept coming to se...\n",
       "25239      0  @peterfacinelli Just make sure its not an inte...\n",
       "25240      0  @tweet_homes gotta watch out for those telemar...\n",
       "25241      0  Gooood morning twitter world. Finally had a lo...\n",
       "\n",
       "[25242 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "22\n",
      "255\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "words = \"alzheimer dementia\".split()\n",
    "for w in words:\n",
    "    print(new_samples[new_samples['tweet'].str.find(w)!=-1]['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = pd.concat([new_samples, df[[\"label\", \"tweet\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_csv(\"data/train_sentiment140.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 29570\n",
      "Negatives: 26613, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_sentiment140.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parental Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25242 0.9 (0.42681772066283397, 0.42681772066283397, 0.04636455867433209)\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.9\n",
    "parent_ratio = 0.5\n",
    "num_samples = int(pos_size * ratio / (1-ratio))\n",
    "num_new = num_samples - neg_size\n",
    "num_parent = num_new // 2\n",
    "num_random = num_new - num_parent\n",
    "\n",
    "num_total = num_samples + pos_size\n",
    "\n",
    "print(num_new, num_samples/num_total, (num_parent/num_total, num_random/num_total, neg_size/num_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"data/sentiment140.csv\", names=[\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"], encoding=\"ISO-8859-1\")\n",
    "new_df = pd.DataFrame({\"label\": np.zeros(len(new_df), dtype=int), \"tweet\": new_df['text'].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>0</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>0</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>0</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>0</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>0</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                              tweet\n",
       "0            0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1            0  is upset that he can't update his Facebook by ...\n",
       "2            0  @Kenichan I dived many times for the ball. Man...\n",
       "3            0    my whole body feels itchy and like its on fire \n",
       "4            0  @nationwideclass no, it's not behaving at all....\n",
       "...        ...                                                ...\n",
       "1599995      0  Just woke up. Having no school is the best fee...\n",
       "1599996      0  TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997      0  Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998      0  Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999      0  happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "\n",
       "[1600000 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"mother\", \"mama\", \"mum\", \"mom\", \"mommy\", \"father\", \"dad\", \"daddy\", \"papa\", \"parent\"]\n",
    "\n",
    "is_parental = []\n",
    "for s in new_df['tweet'].values:\n",
    "    for w in words:\n",
    "        if w in s.lower():\n",
    "            is_parental.append(True)\n",
    "            break\n",
    "    else:\n",
    "        is_parental.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>@msdrama hey missed ya at the meeting  sup mama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>Emily will be glad when Mommy is done training...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0</td>\n",
       "      <td>My mom might have breast cancer won't find out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0</td>\n",
       "      <td>@labelsnotlove   my home town. My mammy called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>Bad news was Dad has cancer and is dying   Goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599890</th>\n",
       "      <td>0</td>\n",
       "      <td>going to south streeeet with kate, hopefully m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599912</th>\n",
       "      <td>0</td>\n",
       "      <td>@ShannonGilliam good luck!!  what an exciting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599929</th>\n",
       "      <td>0</td>\n",
       "      <td>@mom2jwo Woo hoo!!!! Keep working hard my dear!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599939</th>\n",
       "      <td>0</td>\n",
       "      <td>OMG!!!!!!!!!! My dad will be having surgery to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599953</th>\n",
       "      <td>0</td>\n",
       "      <td>any ideaZ on what to get dad for father's day ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48936 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                              tweet\n",
       "86           0    @msdrama hey missed ya at the meeting  sup mama\n",
       "106          0  Emily will be glad when Mommy is done training...\n",
       "147          0  My mom might have breast cancer won't find out...\n",
       "233          0  @labelsnotlove   my home town. My mammy called...\n",
       "379          0  Bad news was Dad has cancer and is dying   Goo...\n",
       "...        ...                                                ...\n",
       "1599890      0  going to south streeeet with kate, hopefully m...\n",
       "1599912      0  @ShannonGilliam good luck!!  what an exciting ...\n",
       "1599929      0  @mom2jwo Woo hoo!!!! Keep working hard my dear!! \n",
       "1599939      0  OMG!!!!!!!!!! My dad will be having surgery to...\n",
       "1599953      0  any ideaZ on what to get dad for father's day ...\n",
       "\n",
       "[48936 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[is_parental]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parent = new_df[is_parental].sample(num_parent)\n",
    "new_random = new_df[np.invert(is_parental)].sample(num_random)\n",
    "new_samples = pd.concat([new_parent, new_random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i wonder if there is a life after Alzheimer's caring. beyond despair. poverty sux but commerce is futile. there is no description. mommy \"\n",
      " \"Hi all haven't been on for 48 hours! Been to visit mum her alzheimers has got so bad was very sad \"\n",
      " 'Just contacted AppleCare cuz my Mac apparently has Alzheimers and the memory is bad. But they were awesome...no Mac for 2 - 3 days '\n",
      " \"Waiting on news about my Grandfather, mom called telling me he didn't have much time left  struggled with Alzheimer's for years now \"\n",
      " 'How do I tell my grandmother (with alzheimers) that her sister (also with alzheimers) just died. Having such a shitty day... ']\n",
      "['@Gianuario dementia and cancer  i feel so bad for him and my grandmother &lt;3'\n",
      " '@PandaDementia But I heard you dripping '\n",
      " \"@PandaDementia  boo...I didn't get a chance to try!\"\n",
      " \"@PandaDementia lol silly girl, I would've if I'd known ;) I do feel badly for you though  But I know the cobbler will be amazing! Mmmm..\"\n",
      " \"@velvetdementia Yep, $75/day + tax (so $80/day) to get into any of the Disney World theme parks.   It's why locals never go to the parks!\"]\n"
     ]
    }
   ],
   "source": [
    "words = \"alzheimer dement\".split()\n",
    "for w in words:\n",
    "    print(new_samples[new_samples['tweet'].str.lower().str.find(w)!=-1]['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = pd.concat([new_samples, df[[\"label\", \"tweet\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_csv(\"data/train_parental.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 29570\n",
      "Negatives: 26613, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_parental.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
