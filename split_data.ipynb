{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into stratified train, val, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5410\n",
      "Negatives: 1714, Positives: 3696\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/all_tweets.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5410 data points\n",
    "Train, Val, Test = 80%, 10%, 10% = 4328, 541, 541\n",
    "\"\"\"\n",
    "\n",
    "negative_indices = np.random.permutation(negatives.index.values)\n",
    "positive_indices = np.random.permutation(positives.index.values)\n",
    "\n",
    "neg_train, neg_val, neg_test = np.split(negative_indices, [round(0.8 * neg_size), round(0.9 * neg_size)])\n",
    "pos_train, pos_val, pos_test = np.split(positive_indices, [round(0.8 * pos_size), round(0.9 * pos_size)])\n",
    "\n",
    "train = np.concatenate((neg_train, pos_train))\n",
    "val = np.concatenate((neg_val, pos_val))\n",
    "test = np.concatenate((neg_test, pos_test))\n",
    "\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(val)\n",
    "np.random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: (Train: 4328, Val: 541, Test: 541)\n",
      "Negatives: (Train: 1371, Val: 172, Test: 171)\n",
      "Positives: (Train: 2957, Val: 369, Test: 370)\n"
     ]
    }
   ],
   "source": [
    "trainset = df.iloc[train]\n",
    "valset = df.iloc[val]\n",
    "testset = df.iloc[test]\n",
    "\n",
    "print(f\"Length: (Train: {len(trainset)}, Val: {len(valset)}, Test: {len(testset)})\")\n",
    "print(f\"Negatives: (Train: {sum(trainset['label']==0)}, Val: {sum(valset['label']==0)}, Test: {sum(testset['label']==0)})\")\n",
    "print(f\"Positives: (Train: {sum(trainset['label']==1)}, Val: {sum(valset['label']==1)}, Test: {sum(testset['label']==1)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.to_csv(\"data/train.csv\", index=False)\n",
    "valset.to_csv(\"data/val.csv\", index=False)\n",
    "testset.to_csv(\"data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Train Data to 50% neg 50% pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from BERTweet.TweetNormalizer import normalizeTweet\n",
    "from eda_nlp.code.eda import eda\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_aug = np.full(neg_size, pos_size // neg_size)\n",
    "num_aug[:pos_size % neg_size] += 1\n",
    "np.random.shuffle(num_aug)\n",
    "num_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sr = 0.1 # synonym replacement\n",
    "alpha_ri = 0.1 # random insertion\n",
    "alpha_rs = 0.0 # random swap\n",
    "alpha_rd = 0.0 # random deletion\n",
    "\n",
    "augmented_negatives = {\"label\": [], \"tweet\": []}\n",
    "\n",
    "for i, line in enumerate(negatives.iloc):\n",
    "    label = line[\"label\"]\n",
    "    sentence = normalizeTweet(line[\"tweet\"])\n",
    "    aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug[i]-1)\n",
    "    for aug_sentence in aug_sentences:\n",
    "        augmented_negatives[\"label\"].append(label)\n",
    "        augmented_negatives[\"tweet\"].append(aug_sentence)\n",
    "\n",
    "augmented_negatives = pd.DataFrame(augmented_negatives)\n",
    "augmented_df = pd.concat([augmented_negatives, positives[[\"label\", \"tweet\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_csv(\"data/train_augment_5050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 5914\n",
      "Negatives: 2957, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_augment_5050.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Train Data to 75% neg 25% pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from BERTweet.TweetNormalizer import normalizeTweet\n",
    "from eda_nlp.code.eda import eda\n",
    "\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4328\n",
      "Negatives: 1371, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 7, ..., 6, 6, 7])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_aug = np.full(neg_size, 3 * pos_size // neg_size)\n",
    "num_aug[:3 * pos_size % neg_size] += 1\n",
    "np.random.shuffle(num_aug)\n",
    "num_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sr = 0.1 # synonym replacement\n",
    "alpha_ri = 0.1 # random insertion\n",
    "alpha_rs = 0.1 # random swap\n",
    "alpha_rd = 0.1 # random deletion\n",
    "\n",
    "augmented_negatives = {\"label\": [], \"tweet\": []}\n",
    "\n",
    "for i, line in enumerate(negatives.iloc):\n",
    "    label = line[\"label\"]\n",
    "    sentence = normalizeTweet(line[\"tweet\"])\n",
    "    aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug[i]-1)\n",
    "    for aug_sentence in aug_sentences:\n",
    "        augmented_negatives[\"label\"].append(label)\n",
    "        augmented_negatives[\"tweet\"].append(aug_sentence)\n",
    "\n",
    "augmented_negatives = pd.DataFrame(augmented_negatives)\n",
    "augmented_df = pd.concat([augmented_negatives, positives[[\"label\", \"tweet\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_csv(\"data/train_augment_7525.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 11828\n",
      "Negatives: 8871, Positives: 2957\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_augment_7525.csv\")\n",
    "print(f\"Length: {len(df)}\")\n",
    "\n",
    "negatives = df[df[\"label\"] == 0]\n",
    "positives = df[df[\"label\"] == 1]\n",
    "\n",
    "neg_size = len(negatives)\n",
    "pos_size = len(positives)\n",
    "\n",
    "print(f\"Negatives: {neg_size}, Positives: {pos_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
